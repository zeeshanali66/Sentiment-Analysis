{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2a8199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\mianz\\anaconda3\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: torch in c:\\users\\mianz\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03cf3ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8664bbff2b184ac2a4af5746952bbad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:  36%|###6      | 189M/517M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mianz\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mianz\\.cache\\huggingface\\hub\\models--j-hartmann--emotion-english-distilroberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf109909c67494bb1a6aaba096075fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/294 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035ddc0a4f2b4940bdceb80668ba6605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a308aea9eb44c6ad55569f1a8182ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e13cdef37141f3a24ee6d4dce7b8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a621490a21274f80933e5d5bf9d5d0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cd6f7ed248463e8136cde135f3201e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Emotions:\n",
      "joy\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the sentiment analysis pipeline for emotion detection\n",
    "emotion_analyzer = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "\n",
    "# Function to analyze mood/emotion\n",
    "def analyze_emotion(text):\n",
    "    result = emotion_analyzer(text)\n",
    "    # Extract only the label (emotion) from the result\n",
    "    emotions = [emotion['label'] for emotion in result]\n",
    "    return emotions\n",
    "\n",
    "# Example conversation (replace with dynamic input later)\n",
    "conversation = [\n",
    "    \"I am feeling great today!\",\n",
    "    \"Thatâ€™s wonderful to hear!\",\n",
    "    \"But I'm also a bit nervous about tomorrow.\"\n",
    "]\n",
    "\n",
    "# Combine all messages into one text\n",
    "text = \" \".join(conversation)\n",
    "\n",
    "# Perform emotion detection on the combined text\n",
    "emotion_result = analyze_emotion(text)\n",
    "\n",
    "# Display the detected emotions\n",
    "print(\"Detected Emotions:\")\n",
    "for emotion in emotion_result:\n",
    "    print(emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94507b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mianz\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.1-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.1-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torchvision-0.22.1-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 508.0 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.5/1.7 MB 508.0 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.8/1.7 MB 508.5 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.8/1.7 MB 508.5 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 546.9 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 546.9 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 546.9 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 546.9 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 546.9 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 546.9 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 546.9 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 377.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 377.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 377.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 377.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 377.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 377.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 377.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 377.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 377.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 377.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 377.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 377.0 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 1.6/1.7 MB 248.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 248.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 248.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 248.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 236.7 kB/s eta 0:00:00\n",
      "Downloading torchaudio-2.7.1-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 0.5/2.5 MB 67.1 kB/s eta 0:00:30\n",
      "   ------------ --------------------------- 0.8/2.5 MB 77.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 0.8/2.5 MB 77.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 0.8/2.5 MB 77.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 0.8/2.5 MB 77.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 0.8/2.5 MB 77.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 0.8/2.5 MB 77.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 0.8/2.5 MB 77.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 0.8/2.5 MB 77.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 0.8/2.5 MB 77.5 kB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 91.3 kB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 91.3 kB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 91.3 kB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 91.3 kB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 91.3 kB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 91.3 kB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 91.3 kB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 91.3 kB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 91.3 kB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 91.3 kB/s eta 0:00:16\n",
      "   --------------------- ------------------ 1.3/2.5 MB 99.0 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 1.3/2.5 MB 99.0 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 1.3/2.5 MB 99.0 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 1.3/2.5 MB 99.0 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 1.3/2.5 MB 99.0 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 1.3/2.5 MB 99.0 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 1.3/2.5 MB 99.0 kB/s eta 0:00:12\n",
      "   ------------------------- -------------- 1.6/2.5 MB 107.4 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.6/2.5 MB 107.4 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.6/2.5 MB 107.4 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.6/2.5 MB 107.4 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.6/2.5 MB 107.4 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.6/2.5 MB 107.4 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.6/2.5 MB 107.4 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 114.9 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 114.9 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 114.9 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 114.9 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 114.9 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 114.9 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 114.9 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 114.9 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 114.9 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 2.1/2.5 MB 119.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 2.1/2.5 MB 119.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 2.1/2.5 MB 119.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 2.1/2.5 MB 119.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 2.1/2.5 MB 119.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 2.1/2.5 MB 119.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 2.1/2.5 MB 119.1 kB/s eta 0:00:04\n",
      "   ------------------------------------- -- 2.4/2.5 MB 123.6 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 2.4/2.5 MB 123.6 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 2.4/2.5 MB 123.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------- 2.5/2.5 MB 127.1 kB/s eta 0:00:00\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "Successfully installed torchaudio-2.7.1 torchvision-0.22.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ca69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "device = 0 if torch.cuda.is_available() else -1  # 0 for GPU, -1 for CPU\n",
    "\n",
    "# Load the emotion detection model and move it to GPU if available\n",
    "emotion_analyzer = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", device=device)\n",
    "\n",
    "# Function to analyze mood/emotion\n",
    "def analyze_emotion(text):\n",
    "    result = emotion_analyzer(text)\n",
    "    # Extract only the label (emotion) from the result\n",
    "    emotions = [emotion['label'] for emotion in result]\n",
    "    return emotions\n",
    "\n",
    "# Start an interactive session\n",
    "print(\"Welcome to the emotion detection chatbot!\")\n",
    "print(\"Type 'exit' to quit.\\n\")\n",
    "\n",
    "while True:\n",
    "    # Get input from the user\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    # Exit condition\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Perform emotion detection on the user input\n",
    "    detected_emotions = analyze_emotion(user_input)\n",
    "\n",
    "    # Display the detected emotion(s)\n",
    "    print(\"Detected Emotions:\")\n",
    "    for emotion in detected_emotions:\n",
    "        print(f\"- {emotion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ea09eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\mianz\\anaconda3\\lib\\site-packages (0.33.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9e9a626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextClassificationOutputElement(label='POS', score=0.9898030757904053), TextClassificationOutputElement(label='NEU', score=0.008573668077588081), TextClassificationOutputElement(label='NEG', score=0.0016232164343819022)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Make sure the Hugging Face token is set in your environment variables\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key='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',  # Using the token from environment variable\n",
    ")\n",
    "\n",
    "# Perform sentiment analysis with the specified model\n",
    "result = client.text_classification(\n",
    "    \"I like you. I love you\",  # Example input text\n",
    "    model=\"finiteautomata/bertweet-base-sentiment-analysis\",  # Model for sentiment analysis\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3e90fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the sentiment analysis chatbot!\n",
      "Type 'exit' to quit.\n",
      "\n",
      "Sentiment Analysis: [TextClassificationOutputElement(label='POS', score=0.9513681530952454), TextClassificationOutputElement(label='NEU', score=0.04565715417265892), TextClassificationOutputElement(label='NEG', score=0.0029747015796601772)]\n",
      "Sentiment Analysis: [TextClassificationOutputElement(label='NEG', score=0.9632411599159241), TextClassificationOutputElement(label='NEU', score=0.03060331754386425), TextClassificationOutputElement(label='POS', score=0.006155489478260279)]\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Use the Hugging Face API key directly in your code (if environment variable is not set)\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=\"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\",  \n",
    ")\n",
    "\n",
    "# Function to perform sentiment analysis on user input\n",
    "def analyze_sentiment(user_input):\n",
    "    # Perform sentiment analysis using the specified model\n",
    "    result = client.text_classification(\n",
    "        user_input,  # Example input text (dynamic)\n",
    "        model=\"finiteautomata/bertweet-base-sentiment-analysis\",  # Model for sentiment analysis\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Start interactive chat session\n",
    "print(\"Welcome to the sentiment analysis chatbot!\")\n",
    "print(\"Type 'exit' to quit.\\n\")\n",
    "\n",
    "while True:\n",
    "    # Get dynamic input from the user\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    # Exit condition\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Perform sentiment analysis on the user input\n",
    "    result = analyze_sentiment(user_input)\n",
    "\n",
    "    # Print the sentiment result\n",
    "    print(f\"Sentiment Analysis: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8799ae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the emotion detection chatbot!\n",
      "Type 'exit' to quit.\n",
      "\n",
      "Detected Emotion: POS\n",
      "Detected Emotion: NEG\n",
      "Detected Emotion: NEG\n",
      "Detected Emotion: POS\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Use the Hugging Face API key directly in your code (if environment variable is not set)\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=\"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\",  # Replace with your actual API key\n",
    ")\n",
    "\n",
    "# Function to perform sentiment analysis on user input\n",
    "def analyze_sentiment(user_input):\n",
    "    # Perform sentiment analysis using the specified model\n",
    "    result = client.text_classification(\n",
    "        user_input,  # Example input text (dynamic)\n",
    "        model=\"finiteautomata/bertweet-base-sentiment-analysis\",  # Model for sentiment analysis\n",
    "    )\n",
    "    \n",
    "    # Extract only the emotion label (e.g., POSITIVE, NEGATIVE) from the result\n",
    "    emotion = result[0]['label']\n",
    "    return emotion\n",
    "\n",
    "# Start interactive chat session\n",
    "print(\"Welcome to the emotion detection chatbot!\")\n",
    "print(\"Type 'exit' to quit.\\n\")\n",
    "\n",
    "while True:\n",
    "    # Get dynamic input from the user\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    # Exit condition\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Perform sentiment analysis on the user input\n",
    "    emotion = analyze_sentiment(user_input)\n",
    "\n",
    "    # Print the detected emotion\n",
    "    print(f\"Detected Emotion: {emotion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ef9292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\mianz\\anaconda3\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\mianz\\anaconda3\\lib\\site-packages (0.33.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from flask) (1.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mianz\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41678757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.18.46:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [22/Jun/2025 20:31:37] \"POST / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [22/Jun/2025 20:31:47] \"POST / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [22/Jun/2025 20:34:18] \"POST / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [22/Jun/2025 20:34:19] \"POST / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [22/Jun/2025 20:36:16] \"POST /detect_emotion HTTP/1.1\" 400 -\n",
      "127.0.0.1 - - [22/Jun/2025 20:37:26] \"POST /detect_emotion HTTP/1.1\" 400 -\n",
      "127.0.0.1 - - [22/Jun/2025 20:39:14] \"POST /detect_emotion HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "\n",
    "# Initialize the Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Use the Hugging Face API key directly in your code\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=\"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\",  # Replace with your actual API key\n",
    ")\n",
    "\n",
    "# Function to perform sentiment analysis (emotion detection)\n",
    "def analyze_sentiment(user_input):\n",
    "    result = client.text_classification(\n",
    "        user_input,  # Example input text (dynamic)\n",
    "        model=\"finiteautomata/bertweet-base-sentiment-analysis\",  # Model for sentiment analysis\n",
    "    )\n",
    "    \n",
    "    # Extract only the emotion label (e.g., POSITIVE, NEGATIVE) from the result\n",
    "    emotion = result[0]['label']\n",
    "    return emotion\n",
    "\n",
    "# API endpoint to handle emotion detection\n",
    "@app.route('/detect_emotion', methods=['POST'])\n",
    "def detect_emotion():\n",
    "    try:\n",
    "        # Get the text from the request body\n",
    "        data = request.get_json()\n",
    "        user_input = data['text']  # Extract the text\n",
    "\n",
    "        # Perform emotion detection on the user input\n",
    "        emotion = analyze_sentiment(user_input)\n",
    "\n",
    "        # Return the detected emotion as JSON\n",
    "        return jsonify({\"emotion\": emotion})\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any errors and return an error message\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "# Run the Flask app\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
